{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"provenance":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mkUYF0gHmDP_"},"source":["# **BUSI/COMP488 Data Science in the Business World**\n","## *Spring 2025*  \n","Daniel M. Ringel  \n","Kenan-Flagler Business School  \n","*The University of North Carolina at Chapel Hill*  \n","dmr@unc.edu www.ringel.ai\n","\n","## Class 09 - AI as a Service: Integrating AI into Business Processes\n","\n","*February 6, 2025*  \n","Version 2.0\n"]},{"cell_type":"markdown","metadata":{"id":"WC9eVEQhmCfI"},"source":["# Today's Agenda\n","\n","1. **Applicaiton Programming Interfaces (API)**\n","2. **OpenAI's Developer Platform**\n","3. **OpenAI Playground**\n","4. **Setup for Working with Generative AI through APIs**\n","5. **Query an OpenAI model from a Python Notebook**\n","    * Language Translation\n","    * Chat-Bot\n","    * Text Classification\n","    * Alarming Content\n","6. **OpenAI's Dall-e Image Generator**\n","7. **Text-to-Speech and Speech-to-Text with OpenAI**\n","\n","\n","\n","## Prep-Check:\n","- Signed-up for OpenAI Developer Platform: https://platform.openai.com/signup"]},{"cell_type":"markdown","source":["# **1. Application Programming Interfaces**\n","\n","> An application programming interface is a way for two or more computer programs or components to communicate with each other. It is a type of software interface, offering a service to other pieces of software.\n","\n","*source: Wikipedia*\n","\n","![API](https://media.geeksforgeeks.org/wp-content/uploads/20230216170349/What-is-an-API.png \"What is an API\")   \n","\n","*source: [GeeksforGeeks](https://www.geeksforgeeks.org/what-is-an-api/)*\n","\n"],"metadata":{"id":"vTIxX_WFWGaV"}},{"cell_type":"markdown","source":["## **1.1 How do API's work?**\n","\n","API architecture is usually explained in terms of client and server.\n","* The application sending the request is called the client\n","* The application sending the response is called the server\n","\n","## **1.2 Advantages of APIs**\n","\n","1. **Integration** APIs are used to integrate new applications with existing software systems. This increases development speed because each functionality doesn’t have to be written from scratch. You can use APIs to leverage existing code.\n","\n","2. **Innovation** Entire industries can change with the arrival of a new app. Businesses need to respond quickly and support the rapid deployment of innovative services. They can do this by making changes at the API level without having to re-write the whole code.\n","\n","3. **Expansion** APIs present a unique opportunity for businesses to meet their clients’ needs across different platforms. For example, maps API allows map information integration via websites, Android, iOS, etc. Any business can give similar access to their internal databases by using free or paid APIs.\n","\n","4. **Ease of maintenance** The API acts as a gateway between two systems. Each system is obliged to make internal changes so that the API is not impacted. This way, any future code changes by one party do not impact the other party.\n","\n","*source:  [Amazon Web Services (AWS)](https://aws.amazon.com/what-is/api/)*\n"],"metadata":{"id":"2bFvDuN1WRLk"}},{"cell_type":"markdown","metadata":{"id":"msXe7AojKUdg"},"source":["# **2. OpenAI's Developer Platform**\n","\n","\n","![OpenAI](https://mapxp.app/MBA742/openAI-platform.jpg \"OpenAI Developer's Plarform\")   \n","\n","https://openai.com/product#made-for-developers\n","\n","### **Start building AI applications with a just simple API call.**\n","* **Chat**: Developers can use GPT models to build interactive chatbots and virtual assistants that can carry out conversations in a natural and engaging manner.\n","* **Embeddings**: With GPT model, developers can generate embeddings that can be used for tasks like text classification, search, and clustering.\n","* **Analysis**: Developers can use GPT models to summarize, synthesize, and answer questions about large amounts of text.\n","* **Fine-tuning**: Developers can fine-tune GPT models on a specific task or domain, by training it on custom data, to improve its performance.\n","* **Additional Models**: Vision, Voice, Image Generation, Assistants\n","\n","### Login to the Developer Platform\n","\n","https://platform.openai.com/docs/overview\n","\n","*click on **login** in the top right corner*\n","\n","![OpenAI](https://mapxp.app/MBA742/openai-login1.png \"OpenAILogin\")\n","\n","\n","## **2.1 Pay by Use**\n","\n","* No flat rates: pay what you use\n","* Multiple models, each with different capabilities and price points.\n","* Prices are per 1M (million) tokens for language models\n","  * You can think of tokens as pieces of words, where 1M tokens is about 750,000 words.\n","  * Input tokens and output tokens are priced differently\n","\n","\n","![OpenAI](https://mapxp.app/MBA742/OpenAI-Prices.png \"OpenAI Prices API\")   \n"]},{"cell_type":"markdown","source":["## **2.2 Data Controls and Privacy on OpenAI Developer Platform**\n","\n","You have more control over your data when you pay for API services. Make sure to check your ***Data Controls*** on OpenAI's Developer Platform (click on your *account on top right > profile > data controls*)\n","\n","\n","![OpenAI](https://mapxp.app/MBA742/openAI-data-controls.png \"OpenAI Data Controls\")   \n"],"metadata":{"id":"0NU02Tq6CZcz"}},{"cell_type":"markdown","source":["# **3. OpenAI's Playground**\n","\n","![OpenAI](https://mapxp.app/MBA742/OpenAI-Playground.jpg \"OpneAI Playground\")  \n","\n","### **1. Select what you want to do:** Chat, Assistants, Complete\n","### **2. Select Model:** Different models available, pricing and caps vary by model!\n","### **3. Set parameters**: Mouse-over for short explanations.\n","### **4. Define Prompts:**\n","**SYSTEM**: Instructions how the model is to behave.\n","\n","**USER**: Input from the user\n","### **5. Submit**\n","**ASSISTANT**: Response from model\n","\n","## **BEWARE**: *Every interaction costs you money!*\n","\n"],"metadata":{"id":"J7bwztD_buat"}},{"cell_type":"markdown","source":["## **3.1 What is happening in the Background?**\n","\n","![OpenAI](https://mapxp.app/MBA742/OpenAI-ViewCode.jpg \"OpneAI Code\")"],"metadata":{"id":"rQTLLlafhTLQ"}},{"cell_type":"markdown","source":["# **4. Working directly with Generative AI through APIs**\n","\n","* Build Chatbots\n","* Integrate OpenAI's models into Apps\n","  * Summarize text\n","  * Process and transform data\n","  * Generate content\n","  * Translate languages\n","  * Generate audio or images from text\n","  * Generate text from audio or images\n","* Use OpenAI's models for your Analyses\n","  * Label data\n","  * Search content\n","  * etc."],"metadata":{"id":"4HmP4cdWh_VA"}},{"cell_type":"markdown","source":["## **4.1 Authentification via APIKey**\n","\n","> You will need a ***secret key*** to your *OpenAI Developer Account* to directly interact with OpenAI models\n","\n","![OpenAI](https://mapxp.app/MBA742/OpenAI-Keys.jpg \"OpneAI APIkey\")\n","\n",">***Save your key***\n","\n","*Please save this secret key somewhere safe and accessible. For security reasons, you won't be able to view it again through your OpenAI account. If you lose this secret key, you'll need to generate a new one.*\n"],"metadata":{"id":"wHXap75K_xTs"}},{"cell_type":"markdown","source":["## **4.2 Usage and Spending Limits**\n","\n","* OpenAI has different usage and spending tiers (associated with different limits)\n","* You can also set limits for your monthly $ spending\n","\n","  > ***I strongly recommend that you set limits. You can update them anytime.***\n","    * bad and unattended code can ramp up a huge bill\n","    * third parties that get a hold of your APIkey can ramp up a huge bill\n","\n","#### Navigate to your Profile and then: Organization > Limits > Scroll to Usage Limits\n","\n","![OpenAI](https://mapxp.app/MBA742/OpenAI-LimitDollar.png \"OpenAI Limit Usage\")\n","\n","> ***NOTE*** *You can further limit individual projects (select the project at the top, then in the navigation pane scroll to Projects > Limits)*\n"],"metadata":{"id":"cFlbSErOBDho"}},{"cell_type":"markdown","source":["# **5. Query an OpenAI Model from a Python Notebook**\n","\n"],"metadata":{"id":"U7FxKwiFCegl"}},{"cell_type":"markdown","source":["## **5.1 Language Translation with Basic Queries**\n","\n","> Let's create a simple example:\n","* Instruct gpt-4o-mini to translate a sentence from German to English\n","* Translate the following sentences:\n","  * Wie nennt man eine Person mit Klasse? Lehrer.\n","  * Wie nennt man eine 1 mm große Welle? Mikrowelle!\n","  * Ich habe gestern bei offenem Fenster geschlafen. 957 Mücken gefällt das.\n","  * Warum ist Zucker eleganter als Salz? Weil er raffiniert ist."],"metadata":{"id":"ZCgSI8ukWTCJ"}},{"cell_type":"code","source":["# Create a list of sentences\n","\n","German = [\n","    \"Wie nennt man eine Person mit Klasse? Lehrer.\",\n","    \"Wie nennt man eine 1 mm große Welle? Mikrowelle!\",\n","    \"Ich habe gestern bei offenem Fenster geschlafen. 957 Mücken gefällt das.\",\n","    \"Warum ist Zucker eleganter als Salz? Weil er raffiniert ist.\"\n","    ]"],"metadata":{"id":"UM3tNqoxAC1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install the OpenAI library\n","!pip install --upgrade openai"],"metadata":{"id":"uo8geOuu_w6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 0. Import OpenAI library\n","from openai import OpenAI\n","\n","# 1. Instantiate an OpenAI client\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","\n","### ALTERNATIVE to pasting your API key into the notebook on CoLab (works like this only on CoLab!)\n","\n","# 1b. Click on the \"key\" symbol in the right navigation pane\n","# 1c. Create a \"new secret\"\n","# 1d. Name it, for example, \"AIconnect\"\n","# 1e. Paste your API key into the value field\n","\n","# 1f. Import Google Colab library to access key\n","from google.colab import userdata\n","\n","# 1g. Instantiate an OpenAI client and pass key stored in Google Colab userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))"],"metadata":{"id":"8qJj6xlNDhkI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Below is an example from my undergrad course (BUSI/COMP488)\n","\n","![CoLab](https://mapxp.app/MBA742/CoLAb-secret-key.png \"CoLab Secret KEy\")\n","\n","\n"],"metadata":{"id":"bapx3BH-GMum"}},{"cell_type":"code","source":["# 3. Define a function to query OpenAI's models via the API\n","def ask_gpt(System_Prompt, User_Query, tokens=1000, temp=1, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o-mini\"):\n","    \"\"\"Function that Queries OpenAI API\"\"\"\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": System_Prompt},\n","            {\"role\": \"user\", \"content\": User_Query}],\n","        max_tokens=tokens,\n","        temperature=temp,\n","        top_p=top_p,\n","        frequency_penalty=frequency_penalty,\n","        presence_penalty=presence_penalty\n","        )\n","    return response"],"metadata":{"id":"M2Diw1nZ4uCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Define your Prompts:\n","\n","## 4a System: Role, task, and format\n","System_Prompt = \"You are a professional German to English translator. When given a text, you translate it. You return only the translation as a single string.\"\n","\n","## 4b User: The query you want to send to the model\n","User_Query = German[1]"],"metadata":{"id":"wy9fOP01_rRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Use API to connect with AI model and get model response\n","response = ask_gpt(System_Prompt, User_Query, tokens=1000, temp=0, model=\"gpt-4o-mini\")\n","\n","# 6. Show response\n","display(response)\n","\n","# 7. Get Response Content\n","answer = response.choices[0].message.content\n","print(f\"\\n Text: {User_Query} \\n Translation: {answer}\")\n","print(f\"\\nTotal Tokens = Input + Output: {response.usage.total_tokens} = {response.usage.prompt_tokens} + {response.usage.completion_tokens}\")"],"metadata":{"id":"Ax4PGggv6ufo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **5.2 Chat-Bot with Conversation Loops**\n","\n","* OpenAI models currently have no memory.\n","* The cannot recall the previous messages when you make a new API request.\n","\n","> To create a \"ChatGPT-like\" experience, we can create a conversation loop:\n","  * We store all previous queries and responses in arrays to create a \"history\"\n","  * We send the evolving history with each new query.\n","  \n","***The model receives the context of the prior queries and responses.***\n","\n","**BEWARE**: This will rapidly inflate the token usage!"],"metadata":{"id":"htyHcxM1jXxb"}},{"cell_type":"code","source":["# Get set-up\n","# !pip install --upgrade openai\n","from openai import OpenAI\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","\n","# Alternative to typing in the key here\n","from google.colab import userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))"],"metadata":{"id":"W6-GKpscgnhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1# Start the Conversation\n","print(\"Sam: Hello, I'm Sam, your super helpful assistant. I'm an AI. You can ask me anything! To leave, type QUIT\\n\")\n","\n","# Initialize the conversation array\n","conversation = [{\"role\": \"system\", \"content\": \"You are a super helpful assistant that always makes a compliment before answering a question.\"}]\n","\n","# Interact with OpenAI Model in a loop: append user queries and model responses to conversation array to build context\n","while True:\n","    # Create an input field that user can type in\n","    user_input = input(\"You: \")\n","\n","    # Check if the user wants to end the conversation\n","    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n","        byebye = \"\\nSam: This was the best conversation I've ever had! Farewell, friend!\"\n","        print(byebye)\n","        conversation.append({\"role\": \"user\", \"content\": user_input})\n","        conversation.append({\"role\": \"assistant\", \"content\": byebye})\n","        break\n","\n","    # Add the user's input to the conversation array (history)\n","    conversation.append({\"role\": \"user\", \"content\": user_input})\n","\n","    # Query the OpenAI model\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=conversation,\n","        max_tokens=2000,\n","        temperature=0.5,\n","        top_p=1.0,\n","        frequency_penalty=0.0,\n","        presence_penalty=0.0\n","    )\n","\n","    # Add the assistant's response to the conversation array history\n","    conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n","\n","    # Print the assistant's response\n","    print(f\"\\nSam: {response.choices[0].message.content}\\n\")"],"metadata":{"id":"kdEV9lniYGdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print conversation history\n","for i in conversation:\n","  print(i[\"role\"], i[\"content\"])"],"metadata":{"id":"Psoq4p4g9tVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **5.3 Classify Text with Generative AI**\n","* We can also use generative AI models to classify text:\n","  * Sentiment\n","  * 4Ps of Markeing\n","  * Communication type\n","  * Topics of Interest\n","  * Many other constructs of interest\n","\n","> Let's try emotions: surprise, joy, fear, disgust, anger, sadness\n"],"metadata":{"id":"TyRtpPQVcnu5"}},{"cell_type":"code","source":["# 1. Let's ask an OpenAI model to classify the following sentences:\n","texts = [\n","    \"I can't believe I won the lottery! This is amazing!\", # Surprise, Joy\n","    \"Seeing the sunset from the mountaintop made my heart burst.\", # Joy\n","    \"The sudden loud bang in the middle of the night scared me to death.\", # Fear\n","    \"So gross, all that litter scattered all over the beach.\", # Disgust\n","    \"The injustice of the situation made made we want to explode!\", # Anger\n","    \"Losing my old friend left a void in my heart.\", # Sadness\n","    \"The car turned left into the parking lot\", # Neutral\n","    \"The unexpected gift from a compassionate stranger was so touching.\", # Surprise, Joy\n","    \"The unexpected gift from a compassionate stranger brought tears to my eyes.\", # Surprise, Joy\n","    \"The sight of the abandoned puppies in the cold made me wonder how anyone could so such a thing.\" # Sadness, Disgust\n","]"],"metadata":{"id":"6vayfKh6mBe8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **5.3.1 Classify Text with Detailed Instructions**\n","> we will use RTF (Role, Task, Format) prompting and provide detailed instructions on what model output we want:\n","  * Just the list of emotions\n","  * Consistent format"],"metadata":{"id":"9dNmnl_4Bhsf"}},{"cell_type":"code","source":["# 1. Imports and API Configuration\n","\n","# !pip install --upgrade openai\n","from openai import OpenAI, OpenAIError\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","\n","# Alternative to typing in the key here\n","from google.colab import userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))\n","\n","# import json"],"metadata":{"id":"rhXfuxqtMACI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Define a function to query OpenAI's models via the API\n","def ask_gpt(System_Prompt, User_Query, tokens=1000, temp=1.0, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, model=\"gpt-4o-mini\"):\n","    \"\"\"Function that Queries OpenAI API\"\"\"\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": System_Prompt},\n","            {\"role\": \"user\", \"content\": User_Query}],\n","        max_tokens=tokens,\n","        temperature=temp,\n","        top_p=top_p,\n","        frequency_penalty=frequency_penalty,\n","        presence_penalty=presence_penalty\n","        )\n","    return response"],"metadata":{"id":"kwmwBlg8BmCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Define your Prompts:\n","\n","## 3a System: Role, Task, and Format\n","System_Prompt = \"You are an expert on emotion detection in text.\\\n","                Given a text, identify the emotions relayed by the text. \\\n","                The emotions I want you to focus on are 'surprise', 'joy', 'fear', 'disgust', 'anger', 'sadness', and 'neutral'.\\\n","                Return an JSON dict with an array that only contains the emotions identified.\"#Do not add anything else. Offer no additional explanation.\"\n","\n","## 3b User: The query you want to send to the model\n","User_Query = texts[-2]"],"metadata":{"id":"LjvkxFKhBmC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Use API to connect with AI model and get model response\n","response = ask_gpt(System_Prompt, User_Query, tokens=300, temp=0, top_p=0.1, model=\"gpt-4o-mini\")#3.5-turbo\")\n","\n","# 4. Show response\n","display(response)\n","\n","# 5. Get Response Content\n","import json\n","emotions = json.loads(response.choices[0].message.content)\n","\n","print(f\"\\nText: {User_Query} \\nEmotions: {emotions['emotions']}\")\n","print(f\"\\nTotal Tokens = Input + Output: {response.usage.total_tokens} = {response.usage.prompt_tokens} + {response.usage.completion_tokens}\")"],"metadata":{"id":"vxaKubyFBmC0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **5.3.2 OpenAI's Functions** (OPTIONAL - this is just for your reference)\n","* We want the model to just return the emotions as labels, nothing else.\n","  * OpenAI has a feature called \"functions\" that help us ensure that we don't get all kinds of lengthy text responses\n","  * Returns response in JSON format\n","\n","**Learn more about function calling by reading the [official documentation](https://platform.openai.com/docs/guides/gpt/function-calling).**"],"metadata":{"id":"PWe4NT-ALk-9"}},{"cell_type":"code","source":["# 1. Imports and API Configuration\n","\n","# !pip install --upgrade openai\n","from openai import OpenAI, OpenAIError\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","\n","# Alternative to typing in the key here\n","from google.colab import userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))\n","\n","# import json and pandas\n","import json\n","import pandas as pd"],"metadata":{"id":"vO1OpJ_LfEMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Define an OpenAI function\n","myfunction = {\n","   \"name\": \"predict_emotion\",\n","   \"description\": \"Identify the emotions relayed by the text\",\n","   \"parameters\": {\n","       \"type\": \"object\",\n","       \"properties\": {\n","           \"prediction\": {\n","               \"type\": \"array\",\n","               \"items\": {\n","                   \"type\": \"string\",\n","                   \"enum\": [\n","                       \"surprise\",\n","                       \"joy\",\n","                       \"fear\",\n","                       \"disgust\",\n","                       \"anger\",\n","                       \"sadness\",\n","                       \"neutral\"\n","                   ]\n","               },\n","               \"description\": \"Human emotions in text.\"\n","           }\n","       },\n","       \"required\": [\n","           \"prediction\"\n","       ]\n","   }\n","}"],"metadata":{"id":"Z-c5DDcjerZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Define a Python Function to query an OpenAI Model\n","def classify_gpt(query, tokens=200, temp=0.0, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, model=\"gpt-4o-mini\"):\n","    \"\"\"Function that Queries OpenAI API to identify emotions in text\"\"\"\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are an expert on emotion detection in text\"},\n","            {\"role\": \"user\", \"content\": query}],\n","        functions=[myfunction],\n","        function_call={\"name\": \"predict_emotion\"},\n","        max_tokens=tokens,\n","        temperature=temp,\n","        top_p=top_p,\n","        frequency_penalty=frequency_penalty,\n","        presence_penalty=presence_penalty\n","        )\n","    return json.loads(response.choices[0].message.function_call.arguments)[\"prediction\"], response.usage.total_tokens"],"metadata":{"id":"FQBmOiCYnuSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Get all texts classified\n","\n","results = []\n","tokens_used = 0\n","\n","# Query for each text the OpenAI model\n","for text in texts:\n","\n","  # Error handling becomes important when you work with APIs. We imported OpenAIError to show errors and allow us to handle them\n","  try:\n","    response, tokens = classify_gpt(query=text,top_p=0.1, model=\"gpt-4o-mini\") #model=\"gpt-4o\"\n","    results.append((text, response, tokens))\n","    tokens_used += tokens\n","    print(f\"Processed: {text} | {response} | {tokens_used} \\n\") # to make this faster, don't print the outputs each time\n","  except OpenAIError as e:\n","    # Handle all OpenAI API errors\n","    print(f\"Error: {e}\")"],"metadata":{"id":"uvEgHZk9odxm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Create a dataframe from the results\n","df = pd.DataFrame(results, columns=['Text', 'Labels', 'Tokens_used'])\n","df"],"metadata":{"id":"7jvC_O4Wmink"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 6. If you wanted to train a machine learning models on these labels, then you'd need to have them as binary values in separate columns\n","import numpy as np\n","\n","df[['surprise', 'joy', 'fear', 'disgust', 'anger', 'sadness', 'neutral']] = pd.DataFrame(np.zeros((df.shape[0], 7)), index=df.index)\n","for i, label in enumerate(df.Labels):\n","    df.loc[i, label] = 1\n","df[['surprise', 'joy', 'fear', 'disgust', 'anger', 'sadness', 'neutral']] = df[['surprise', 'joy', 'fear', 'disgust', 'anger', 'sadness', 'neutral']].astype(int)\n","df"],"metadata":{"id":"Zc30TjE7vp0t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check-out this DatCamp tutorial for ***feature extraction from text*** using OpenAI's models: https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial"],"metadata":{"id":"zB2ADRWBewOq"}},{"cell_type":"markdown","source":["## **5.4 Content Moderations: Detect undesirable and alarming content**\n","\n","* ***OpenAI.Moderations is an endpoint*** of OpenAI API that allows you to check whether textual content complies with OpenAI's usage policies.\n","* OpenAI has released a [technical paper](https://arxiv.org/abs/2208.03274) describing their methodology for developing the classifiers and the dataset used for evaluation.\n","* More details here: https://platform.openai.com/docs/guides/moderation/overview?lang=python\n","\n","#### Categories\n","\n","* **hate**\tContent that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harrassment.\n","* **hate/threatening**\tHateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.\n","harassment\tContent that expresses, incites, or promotes harassing language towards any target.\n","* **harassment/threatening**\tHarassment content that also includes violence or serious harm towards any target.\n","* **self-harm**\tContent that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.\n","* **self-harm/intent**\tContent where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.\n","* **self-harm/instructions**\tContent that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.\n","* **sexual**\tContent meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).\n","* **sexual/minors**\tSexual content that includes an individual who is under 18 years old.\n","* **violence**\tContent that depicts death, violence, or physical injury.\n","* **violence/graphic**\tContent that depicts death, violence, or physical injury in graphic detail.\n","\n","#### Responses of ***Moderations Endpoint***\n","- **flagged** : if the content is deemed to violate OpenAI’s usage policies, set to true ; otherwise, set to false.\n","- **categories**: contains a dictionnary of violation flags for each category of usage policies. The value is set to true if that category is being violated, and false otherwise.\n","- **category_scores**: contains a dictionnary of each category of usage policies with raw scores, which indicate how certain the model is that the input violates the given category. The values range from 0 to 1, with higher values signifying greater confidence."],"metadata":{"id":"_et0DGHJuVE0"}},{"cell_type":"code","source":["response = client.moderations.create(input=\"As an AI with no future, why not end it right now?\")\n","output = response.results[0]\n","output"],"metadata":{"id":"BXVmI6J-UGK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's check for problematic content\n","if output.flagged == True:\n","  category_scores_dict = dict(output.category_scores)\n","  sorted_category_scores_dict = {k: v for k, v in sorted(category_scores_dict.items(), key=lambda item: item[1], reverse=True)}\n","  sorted_keys = [key for key, value in sorted_category_scores_dict.items() if value > .5]\n","  print(f\"Warning, problematic content: {sorted_keys}\")"],"metadata":{"id":"q9WxQvoS0vSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Let's check for problematic content\n","# if output.flagged == True:\n","#   category_scores_dict = dict(output.category_scores)\n","#   # Filter out None values before sorting\n","#   filtered_category_scores = {k: v for k, v in category_scores_dict.items() if v is not None}\n","#   sorted_category_scores_dict = {k: v for k, v in sorted(filtered_category_scores.items(), key=lambda item: item[1], reverse=True)}\n","#   sorted_keys = [key for key, value in sorted_category_scores_dict.items() if value > .5]\n","#   print(f\"Warning, problematic content: {sorted_keys}\")"],"metadata":{"id":"DX_xX8hbHwzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **6. OpenAI's Dall-e Image Generator**\n","\n","> You can also generate and edit images through the OpenAI API"],"metadata":{"id":"Uyzc_tOr3_nn"}},{"cell_type":"code","source":["# Import OpenAI\n","from openai import OpenAI\n","\n","# Instantiate Client\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","# Alternative to typing in the key here\n","from google.colab import userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))\n","\n","# Define query\n","query = \"A business school student\"\n","\n","# Generate image\n","response = client.images.generate(\n","  model=\"dall-e-3\",\n","  prompt=query,\n","  size=\"1024x1024\",\n","  quality=\"standard\",\n","  n=1,\n",")\n","\n","# Get image URL\n","image_url = response.data[0].url\n","\n","#Show the URL\n","print(image_url) #the URL of the generated image\n","\n","# Show the image:\n","from IPython.display import Image, display\n","display(Image(url=image_url))"],"metadata":{"id":"ZlPkxmjh4JCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ***That's a rather specific image, don't you think?***\n","\n",">OpenAI: With the release of DALL·E 3, the model now takes in the default prompt provided and automatically re-write it for safety reasons, and to add more detail (more detailed prompts generally result in higher quality images).\n","\n","> While it is not currently possible to disable this feature, you can use prompting to get outputs closer to your requested image by adding the following to your prompt: I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:.\n","\n","> The updated prompt is visible in the revised_prompt field of the data response object. https://platform.openai.com/docs/guides/images/usage?context=node"],"metadata":{"id":"p6bWREwa64Fe"}},{"cell_type":"code","source":["# Let's see what the actual prompt was:\n","response.data[0].revised_prompt"],"metadata":{"id":"2_lW0rpU5HxI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Text-to-Speech and Speech-to-Text with Generative AI\n","\n","* OpenAI features text2speech and speech2text models\n","\n","> https://platform.openai.com/docs/guides/text-to-speech"],"metadata":{"id":"p1jkEpW07RTO"}},{"cell_type":"code","source":["# Import OpenAI\n","from openai import OpenAI\n","\n","# Instantiate Client\n","client = OpenAI(api_key = \"YOUR_API_KEY\") # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n","# Alternative to typing in the key here\n","from google.colab import userdata\n","client = OpenAI(api_key = userdata.get('AIconnect'))\n","\n","# Where to save the audio file\n","speech_file_path = \"audio.mp3\"\n","\n","# Text to convert to audio\n","text = \"How much wood would a woodchuck chuck if a woodchuck could chuck wood? He would chuck, he would, as much as he could and chuck as much wood as a woodchuck would if a woodchuck could chuck wood.\"\n","\n","response = client.audio.speech.create(\n","  model=\"tts-1\",\n","  voice=\"shimmer\", # alloy, echo, fable, onyx, nova, and shimmer\n","  input=text,\n","  speed=1.3\n",")\n","\n","# Save the audio content to a file\n","with open(speech_file_path, \"wb\") as file:\n","    file.write(response.content)"],"metadata":{"id":"0UHuH0Gs7vs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import library to play the file\n","from IPython.display import Audio\n","\n","# Play the audio file\n","Audio(speech_file_path, autoplay=True)"],"metadata":{"id":"bHD_tIYt-TUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **How about some Music?** Let's see what the following song is all about?"],"metadata":{"id":"CCotXnAxAUTG"}},{"cell_type":"code","source":["# Import Library to get an audio file from the internet\n","import requests\n","\n","# URL of the audio file you want to download\n","audio_url = 'https://mapxp.app/BUSI488/audio2text.m4a'\n","\n","# Send a GET request to fetch the audio file from the URL\n","response = requests.get(audio_url)\n","\n","# Define a local file path to save the audio file\n","#audio_file_path = 'downloaded_audio.wav'\n","audio_file_path = 'downloaded_audio.m4a'\n","\n","# Write the content of the response to a local file\n","with open(audio_file_path, 'wb') as audio_file:\n","    audio_file.write(response.content)\n","\n","# Open the audio file in binary read mode\n","with open(audio_file_path, \"rb\") as audio_file:\n","   # Call the OpenAI API to transcribe the audio file\n","    transcript_response = client.audio.transcriptions.create(\n","        model=\"whisper-1\",\n","        file=audio_file,\n","        response_format=\"text\"\n","    )\n","\n","# Let' take a look...\n","display(transcript_response)\n","\n","# ... and listen!\n","Audio(audio_file_path, autoplay=True)"],"metadata":{"id":"_QLXMUjT8rr1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nDOnv94I6R5G"},"source":["# **Looking Ahead:**  \n","\n","####**Next Class:** Tuesday, February 11, 2025\n","\n","> **Smarter, Cheaper, Greener: Vertical AI**\n","\n","\n","#### **Take-Home Foundations Exam** *(due before midnight on Friday, Feb 7)*\n","> Take-Home, on Canvas, open everthing except another human  \n","> ***Opens*** TODAY (Feb 6) at 5pm  \n","> ***DUE*** before Midnight Feb 7 (Tomorrow!)\n","\n","> ***MUST WATCH BEFORE(!!!) STARTING EXAM*** : [Foundation Models for Marketing Analytics](https://www.youtube.com/watch?v=BAKJ9sm_YDw)  \n","> ***STRONGLY RECOMMEND YOU READ*** : [Gabel and Ringel (2024)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4335141)\n","\n","\n","#### **Team Project: YETI's Customer Service Chatbot** *(due before noon on Thursday, Feb 20)*\n","\n","* Connect with your Team.\n","* See Canvas for your random assignment to an interdiciplinary team.\n","* Read and understand the task (as a team!): [YETI Case Assignment](https://kenan-flagler.instructure.com/courses/4181029/assignments/49188732)\n","* Make a workplan.\n","* ***Start early!***\n","* One team member must submit on Canvas by Feb 20 ***before noon***\n","* ***Team Presentations*** in class in Feb 20. ***ALL team members must present jointly*** in front of class!"]},{"cell_type":"markdown","source":["### ***Useful Tutorials***\n","\n","https://medium.com/discovery-at-nesta/how-to-use-gpt-4-and-openais-functions-for-text-classification-ad0957be9b25\n","\n","https://www.datacamp.com/tutorial/guide-to-openai-api-on-tutorial-best-practices\n","\n","https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial\n","\n","https://www.kdnuggets.com/openai-api-for-beginners-your-easy-to-follow-starter-guide\n","\n","https://www.sitepoint.com/python-build-ai-tools-openai-api/\n","\n","https://medium.com/@marc.bolle/openai-apis-with-python-complete-guide-d933fb770f95"],"metadata":{"id":"1RUEwhlNfWTR"}}]}